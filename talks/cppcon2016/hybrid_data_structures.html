<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta charset="utf-8">
    <link href="https://fonts.googleapis.com/css?family=Oswald|Roboto|Roboto+Mono" rel="stylesheet">
    <style>
      body {
        font-family: 'Roboto', sans-serif;
        font-size: 120%
      }
      a {
        color: #96cbfe;
        text-decoration: initial;
      }
      h1, h2, h3 {
        font-family: 'Oswald', sans-serif;
        font-weight: normal;
      }
      .footnote {
        position: absolute;
        bottom: 2em;
        right: 1em;
      }
      .remark-container {
        background-color: #000;
      }
      .remark-slide-scaler {
        -moz-box-shadow: 0 0 30px #000;
        -webkit-box-shadow: 0 0 30px #000;
        box-shadow: 0 0 30px #000;
      }
      .remark-slide-content {
        background-color: #000;
        background-size: cover;
        background-position: center;
        color: #f8f8f8;
        font-size: 32px;
        text-shadow: 0px 0px 16px #000, 0px 0px 32px #000;
        padding: 0.5em 1em 0.5em 1em
      }
      .remark-slide-content h1 {
        font-size: 85px
      }
      .remark-slide-content h2 {
        font-size: 75px
      }
      .remark-slide-content h3 {
        font-size: 75px
      }
      .remark-code, .remark-inline-code {
        font-family: 'Roboto Mono', monospace;
      }
      .remark-code {
        font-size: 22px;
      }
      .remark-code-line-highlighted {
        background-color: #448;
      }
      .remark-code-span-highlighted {
        background-color: #000;
        border: 5px solid #F00;
        box-shadow: 0 0 30px #F00;
        margin: -5px;
        padding: initial;
      }
      .left-col {
        float: left;
        width: 49%;
      }
      .right-col {
        float: right;
        width: 49%;
      }

      #slide-llvm {
        background-position: -50% 60%;
        background-size: 120%;
      }
      #slide-everything-is-a-pointer img {
        width: 40%;
      }
    </style>
  </head>
  <body>
    <textarea id="source">

name: title-layout
layout: true
class: center, middle, title

---
name: basic-layout
layout: true
class: left, top

---
name: title
template: title-layout

# High Performance Code 201: Hybrid Data Structures
.footnote[Chandler Carruth, <chandlerc@gmail.com>, [@chandlerc1024](https://twitter.com/chandlerc1024)]

???
Intro:
- I'm Chandler Carruth
- I'm the lead for Google's C++ PL platform
- Also one of the core developers on the LLVM open source compiler project

I'm going to walk you through the essential hybrid data structures, describe why
they're fast, and how to use them solve really interesting problems.

---
name: llvm
template: basic-layout
background-image: url(DragonFull.png)

## LLVM
- Performance sensitive
- Hacked on by performance nuts

???
These DS aren't just hypothetical. They actually make up the core data
structures used by the LLVM project. I'll be showing code snippets from that
project, so this is talk will be rooted in real code that is actually in use.

LLVM is a great example because it contains a *lot* of performance sensitive
algorithms that use a wide variety of data structures. And the LLVM project and
developers are performance nuts so it tends to use very well optimized and tuned
utilities.

---
name: core-ds
template: title-layout

## Vectors and sets, and maps, oh my!

???

The core DS set is really this small. A vector, a set, and a map.

Really, its even more simple as the map is built directly out of the set.

---
name: smallvector
template: basic-layout

```
template <typename T, int N>
class SmallVector {
  T *Begin, *End;
  size_t Capacity;
  char Buffer[sizeof(T) * N];

public:
  SmallVector() : Begin((T *)Buffer), End((T *)Buffer), Capacity(N) {}

  // ...
};
```

???
Despite the name "small", this type is used pervasively as the vector type of
choice in LLVM.

This is really the workhorse data structure, not unlike std::vector
- Everything uses it...
- Queue
- Worklist
- stack
- binary heap
- sorted set or map

In essence, just a small size optimized vector
- Useful to skip initial alloc even when large often
- Customizable "small" size makes it flexible for cases where reserving a large
  chunk of the stack is actually the best approach

---
name: why-not-std-vector
template: title-layout

### Why not `std::vector`?<br />Iterator invalidation!

???
One interesting question is why can't we make std::vector support (perhaps
optionally) this kind of small size optimization.

Sadly, we can't because of the iterator invalidation requirements: move cannot
invalidate iterators.

But we don't stop with just this small-size optimized API. There is a
surprisingly important extension to it....

---
name: erase-small-size
template: basic-layout

.left-col[
```
template <typename T, int N>
class SmallVector
    : public SmallVectorImpl<T> {
  char Buffer[sizeof(T) * N];

public:
  SmallVector()
      : SmallVectorImpl((T *)Buffer,
                        (T *)Buffer,
                        N) {}

  // ...
};
```
]
.right-col[
```
template <typename T>
class SmallVectorImpl {
  T *Begin, *End;
  size_t Capacity;

protected:
  SmallVectorImpl(T *Begin, T *End,
                  size_t Capacity);

public:
  iterator begin() { return Begin; }
  iterator end() { return End; }

  void push_back(const T &Element);
  void pop_back();

  // ...
};
```
]

???
`SmallVector` also supports *free* erasure of small size

This trick comes from very careful usage of factoring the design.
- All the relevant APIs for SmallVector are provided by a base class.
- We pass the capacity down as we need it in the large form anyways.
- Allows zero-cost "erasure" of the small size as it is only needed to allocate.

---
name: smalldenseset
template: basic-layout

```
template <typename T, int N, typename Traits = DenseSetTraits<T>>
class SmallDenseSet {
  T *Buckets;
  size_t Size, NumTombstones, BucketsSize;
  char Buffer[sizeof(T) * N];

public:
  SmallDenseSet()
      : Buckets((T *)Buffer), Size(0), NumTombstones(0), BucketsSize(N) {}

  // ...
};

template <typename T> struct DenseSetTraits {
  static T getEmpty();
  static T getTombstone();
  static size_t getHash(const T &X);
  static bool compare(const T &LHS, const T &RHS);
};
```

???
- Not "dense", just uses open addressing and no buckets
- Small-size optimization layered on top
- Can even avoid hashing and just append when *very* small

---
name: smalldensemap
template: basic-layout

```
template <typename KeyT, typename ValueT, int N,
          typename Traits = DenseSetTraits<KeyT>>
class SmallDenseMap {
  typedef std::pair<KeyT, ValueT> PairT;

  PairT *Buckets;
  size_t Size, NumTombstones, BucketsSize;
  char Buffer[sizeof(PairT) * N];

public:
  SmallDenseMap()
      : Buckets((PairT *)Buffer), Size(0), NumTombstones(0), BucketsSize(N) {}

  // ...
};
```

???
The map is essentially the same as the set except for operating on just the
first part of a pair in the buckets. This is a bit awkward to write with one in
terms of the other, so the code here is really just for illustration.

---
name: done
template: title-layout

## We're done.

---
name: elephant
template: title-layout
background-image: url(elephant.jpg)

--

## Why not just use allocators?

???
Very commonly people suggest that rather than using a customized container, we
should be using allocators to do small-size optimization.

---
name: allocators
template: basic-layout

```
template <class T, int N>
using SmallVector =
    std::vector<T, short_alloc<T, N>>;

void f() {
  SmallVector<int, 4>::allocator_type::arena_type a;
  SmallVector<int> v{a};
  // ...
}
```

???
As an example, this is from Howard Hinnant's post suggesting using allocators
to build a SmallVector.

---
name: allocator-interface-boundary
template: basic-layout

```
template <class T, int N>
using SmallVector =
    std::vector<T, short_alloc<T, N>>;

void g(SmallVector<int, 4> &v);

void f() {
  SmallVector<int, 8>::allocator_type::arena_type a;
  SmallVector<int> v{a};
  // ...
  g(v);
}
```

???
However, things become problematic when an allocator based smallvector occurs
in an API boundary.

---
name: allocator-interface-boundary-highlight
template: basic-layout

```
template <class T, int N>
using SmallVector =
    std::vector<T, short_alloc<T, N>>;

void g(SmallVector<int, `4`> &v);

void f() {
  SmallVector<int, `8`>::allocator_type::arena_type a;
  SmallVector<int> v{a};
  // ...
  `g(v);` // BOOOM
}
```

???
As you can see, it is very easy to get mismatches or fail to update everything
in lock step here.

Maybe there is some trick to get something similar to
SmallVectorImpl above, but I don't know how.

---
name: return-small-vector
template: basic-layout

```
template <class T, int N>
using SmallVector =
    std::vector<T, short_alloc<T, N>>;

SmallVector<T, 4> f() {
  SmallVector<int, 4>::allocator_type::arena_type a;
  SmallVector<int> v{a};
  // ...
  return v;
}
```

???
However things get even worse if you want value semantics, for example to
return a small vector.

---
name: return-small-vector-highlight
template: basic-layout

```
template <class T, int N>
using SmallVector =
    std::vector<T, short_alloc<T, N>>;

SmallVector<T, 4> f() {
  SmallVector<int, 4>::allocator_type::arena_type a;
  SmallVector<int> v{a};
  // ...
  `return v;` // You're gonna have a bad time...
}
```

???
Consider this code, where the small vector can be returned by value. Doing this
with an allocator requires passing in the allocator, complicating the code and
making clients aware of the particular small size required.

With smallvector, even though the small size is exposed in the interface, users
typically just use auto and stop caring.

---
name: small-size
template: title-layout

## Small-size optimization is best when the values are *small!*

---
name: make-values-small
template: title-layout

## So how can we make the values *small?*

---
name: address-identity
template: title-layout

## Give large objects *address identity*

???

---
name: vector-unique-ptr
template: basic-layout

```
SmallVector<std::unique_ptr<BigObject>, 4> Objects;
```

???
Really simple technique.

Downsides are that the separate allocation run the risk of undermining the
locality and cache friendliness of the data structures.

---
name: bump-ptr-allocator
template: basic-layout

```
class BumpPtrAllocator {
  constexpr int SlabSize = 4096;
  SmallVector<void *, 4> Slabs;
  void *CurPtr, *End;

public:
  void *Allocate(int Size) {
    if (Size >= (End - CurPtr)) {
      CurPtr = malloc(SlabSize);
      End = CurPtr + SlabSize;
      Slabs.push_back(CurPtr);
    }

    void *Ptr = CurPtr;
    CurPtr += Size;
    return Ptr;
  }

  // ...
};
```

???
To address the separate allocation problem, we often use a slab or "bump
pointer" allocator to allocate objects densely in memory at stable addresses.

Allocating slabs of large objects (especially if they're not uniformly sized)
and then building your set, map, or worklist data structures out of pointers to
them turns out to be incredibly efficient.

Consider, walking a vector of pointers to objects versus walking a list of
objects
- If the list is doubly linked, twice as much overhead
- much harder to have small size optimization keep all the pointers warm in cache
- Fewer dependencies - accessing the next element doesn't depend on accessing
  the first. in highly out-of-order modern processors, this can significantly
  improve their ability to hide memory access latencies


---
name: index-identity
template: title-layout

### If pointers are too large, use an index

???
Sometimes, pointers don't work well or are still too large. In those cases we
will often use counted objects allocated in a single contiguous location and
have *index* identity instead of *address* identity. Same wins as with pointers,
but even more compact data if we can get away with 32bit or smaller indices.

---
name: bitpacking
template: title-layout

## Next, aggressively pack the bits

---
name: everything-is-a-pointer
template: title-layout

![Give me a pointer!](http://imgs.xkcd.com/comics/pointers.png)
.footnote[<http://xkcd.com/138/>]

???
We just made everything a pointer, what can we do with those?

Well, real pointers don't look quite like the ones in xkcd...

---
name: pointer-bits-available
template: basic-layout

```
Breakpoint 1, main () at test.cpp:7
7         S *s = new S;
(gdb) n
8         return 0;
(gdb) p/a s
$2 = 0x402010
(gdb) p/t s
$3 = 10000000010000000010000
```

???
Some of the bits in pointers aren't actually used due to alignment.

When necessary, we can even artificially align the types higher and get more
free bits. As more and more users have 64-bit address spaces, overaligned types
become very effective

---
name: pointer-bits-available-highlight
template: basic-layout

```
Breakpoint 1, main () at test.cpp:7
7         S *s = new S;
(gdb) n
8         return 0;
(gdb) p/a s
$2 = 0x402010
(gdb) p/t s
$3 = 1000000001000000001`0000`
```

???
Some of the bits in pointers aren't actually used due to alignment.

When necessary, we can even artificially align the types higher and get more
free bits. As more and more users have 64-bit address spaces, overaligned types
become very effective

---
name: pointer-int-pair
template: basic-layout

```
template <typename PtrT> struct PointerLikeTraits {
  constexpr int FreeBits = log2(alignof(PtrT));

  static auto getPointer(uintptr_t Value) { return (PtrT)(Value); }
};

template <typename PtrT, int IntBits, typename IntT = unsigned,
          typename PtrTraits = PointerLikeTraits<PtrT>>
class PointerIntPair {
  constexpr int IntShift = PtrTraits::FreeBits - IntBits;
  constexpr uintptr_t IntMask = (uintptr_t)(((intptr_t)1 << IntBits) - 1);
  constexpr uintptr_t PtrMask = ~(uintptr_t)(((intptr_t)1 << PtrTraits::FreeBits) - 1);

  uintptr_t Value;

public:
  auto getPointer() const { return PtrTraits::getPointer(Value & PtrMask); }

  auto getInt() const { return (IntT)((Value >> IntShift) & IntMask); }

  // ...
};
```

???
This lets us combine pointers with small integers. The code ends up being fully
generic.

---
name: pointer-embedded-int
template: basic-layout

```
template <typename IntT, int Bits = sizeof(IntT) * CHAR_BIT>
class PointerEmbeddedInt {
  constexpr int Shift = sizeof(uintptr_t) * CHAR_BIT - Bits;
  uintptr_t Value;

public:
  PointerEmbeddedInt(uintptr_t Value) : Value(Value) {}

  void set(IntT i) { Value = (uintptr_t)(i) << Shift; }
  auto get() const { return (IntT)(Value >> Shift); }
};

template <typename IntT, int Bits>
struct PointerLikeTraits<PointerEmbeddedInt<IntT, Bits>> {
  constexpr int FreBits = sizeof(uintptr_t) * CHAR_BIT - Bits;

  static auto getPointer(uintptr_t Value) {
    return PointerEmbeddedInt<IntT, Bits>(Value);
  }
};
```

???
And it isn't restricted to pointers. It can handle any "pointer like" object.

---
name: pointer-int-pair-nested
template: basic-layout

```
template <typename PtrT, int IntBits, typename IntT, typename PtrTraits>
struct PointerLikeTraits<PointerIntPair<PtrT, IntBits, IntT, PtrTraits>> {
  constexpr int FreeBits = PtrTraits::FreeBits - IntBits;

  // ...
};

PointerIntPair<PointerIntPair<S *, 1, bool>, 1, bool> PtrAndTwoBools;
```

???
And in fact, it is itself a pointer like object! It just consumes some of the
pointer-like alignment provided.

---
name: pointer-sum-type
template: basic-layout

```
template <uintptr_t N, typename PtrT, typename PtrTraits = PointerLikeTraits<T>>
struct PointerSumTypeMember;

template <typename TagT, typename... MemberTs> struct PointerSumTypeHelper;

template <typename TagT, typename... MemberTs> class PointerSumType {
  using HelperT = detail::PointerSumTypeHelper<TagT, MemberTs...>;
  template <TagT N> using TagPtrT = HelperT::template Lookup<N>::PtrT;
  template <TagT N> using TagPtrTraits = HelperT::template Lookup<N>::PtrTraits;

  uintptr_t Value;

public:
  auto getTag() const { return (TagT)(Value & HelperT::TagMask); }
  template <TagT N> bool is() const { return N == getTag(); }

  template <TagT N> auto get() const {
    return TagPtrTraits<N>::getFromInt(is<N>() ? (Value & HelperT::PtrMask) : 0u);
  }
};
```

???
We can then use this to build still more abstractions such as a sum type across
pointer like types with an enum descriminator

---
name: tiny-ptr-vector
template: basic-layout

```
template <typename T> class TinyPtrVector {
  enum State { Inline, Vector };
  typedef SmallVector<T, 4> VecT;
  typedef PointerSumType<State,
                         PointerSumTypeMember<Inline, T>,
                         PointerSumTypeMember<Vector, std::unique_ptr<VecT>>>
      SumT;

  SumT Value;
 
public:
  T &operator[](int i) const {
    if (Value.template is<Inline>()) {
      assert(i == 0);
      return Value.template get<Inline>();
    }
    return (*Value.template get<Vector>())[i];
  }

  // ...
};
```

???
Then we can build another hybrid data structure on top of this by introducing a
vector that is a pointer-like object, AND EVEN HAS A SMALL SIZE OPTIMIZATION!

---
name: dense-map-tiny-ptr-vector
template: basic-layout

```
template <typename KeyT, typename ValueT>
using SmallMultiMap = SmallDenseMap<KeyT, TinyPtrVector<ValueT>>;
```

???
One of the most important applications of this is to nest a vector within a map
with high locality and very good scalaing properties.

---
name: bitfields
template: title-layout

### Lastly, use bitfields everywhere

???
This is boring and well understood. But you pretty often need to combine it
with the techniques outlined above.

---
name: ordering
template: title-layout

## Sometimes, you really need an *ordering*...

???
Hash tables, open addressing and pointers all make this much harder to achieve.

---
name: sort
template: title-layout

### Where possible, sort vectors

???
Sorted vectors are a wonderful thing. If you constantly need the ordering, keep
everything sorted and use appropriate algorithsm to update. If you only
occasionally need things ordered, sort on demand.

Note that everything more complex than sorting also works well here. For
example, in-vector trees and heaps are very fast and excellent structures.

---
name: not-always-ordered
template: title-layout

### What if there's no intrinsic ordering?

---
name: setvector
template: basic-layout

```
template <typename T, int N,
          typename VectorT = SmallVector<T, N>,
          typename SetT = SmallDenseSet<T, N>>
class SmallSetVector {
  SetT S;
  VectorT V;
public:
  bool insert(const T &X) {
    bool Result = S.insert(X).second;
    if (Result) V.push_back(X);
    return Result;
  }

  VectorT::iterator begin() { return V.begin(); }
  VectorT::iterator end() { return V.end(); }

  // ...
};
```

???
A very common pattern in those situations is just to keep a set and a vector.
This gives you insertion-order in the vector but set semantics. LLVM wraps this
up because it is so common. Of course, this delegates to the nicely small-size
optimized routines.

A really useful technique we haven't yet imployed is to take advantage of the
fact that the set is *also* a vector when small to have the small size
optimization be shared.

---
name: mapvector
template: basic-layout

```
template <typename KeyT, typename ValueT, int N,
          typename VectorT = SmallVector<std::pair<KeyT, ValueT>, N>,
          typename MapT = SmallDenseMap<KeyT, int, N>>
class SmallMapVector {
  MapT M;
  VectorT V;
public:
  ValueT &operator[](const KeyT &K) {
    auto InsertResult = M.insert({K, 0});
    int &Index = InsertResult.first->second;
    if (InsertResult.second) {
      V.push_back({K, ValueT()});
      Index = V.size() - 1;
    }
    return V[Index];
  }

  VectorT::iterator begin() { return V.begin(); }
  VectorT::iterator end() { return V.end(); }

  // ...
};
```

???
Naturally, all that applies for sets, applies for maps.

---
name: conclusion
template: title-layout

## 2.5 small size optimized structures, pointers, and bit packing

---
name: questions
template: title-layout

# Questions?

    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create({
        // Set the slideshow display ratio
        // Default: '4:3'
        // Alternatives: '16:9', ...
        ratio: '16:9',

        // Syntax highlighting theme
        highlightLanguage: 'cpp',
        highlightStyle: 'ir-black',
        highlightLines: true,
        highlightSpans: true,

        // Customize slide number label, either using a format string..
        slideNumberFormat: '(%current% / %total%)',
      });
    </script>
  </body>
</html>
