<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta charset="utf-8">
    <link href="https://fonts.googleapis.com/css?family=Oswald|Roboto|Roboto+Mono" rel="stylesheet">
    <style>
      body { font-family: 'Roboto', sans-serif; }
      h1, h2, h3 {
        font-family: 'Oswald', sans-serif;
        font-weight: normal;
      }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      .remark-container {
        background-color: #000;
      }
      .remark-slide-scaler {
        -moz-box-shadow: 0 0 30px #000;
        -webkit-box-shadow: 0 0 30px #000;
        box-shadow: 0 0 30px #000;
      }
      .remark-slide-content {
        background-color: #000;
        color: #f8f8f8;
      }
      .remark-code, .remark-inline-code { font-family: 'Roboto Mono', monospace; }
      .remark-code-line-highlighted {
        background-color: #000;
        border: 5px solid #F00;
        box-shadow: 0 0 30px #F00;
      }
      .remark-code-span-highlighted {
        background-color: #000;
        border: 5px solid #F00;
        box-shadow: 0 0 30px #F00;
      }
    </style>
  </head>
  <body>
    <textarea id="source">

name: layout
layout: true

---
name: title-layout
layout: true
class: center, middle, title

---
name: title
template: title-layout

# High Performance Code 201: Hybrid Data Structures

.footnote[Chandler Carruth, [chandlerc@gmail.com], [@chandlerc1024](https://twitter.com/chandlerc1024)]

???
Intro:
- I'm Chandler Carruth
- I'm the lead for Google's C++ PL platform
- Also one of the core developers on the LLVM open source compiler project

I'm going to walk you through the essential hybrid data structures, describe why
they're fast, and how to use them solve really interesting problems.

---
name: llvm
template: layout
background-image: url(DragonFull.png)

## LLVM
- Performance sensitive
- Hacked on by performance nuts

???
These DS aren't just hypothetical. They actually make up the core data
structures used by the LLVM project. I'll be showing code snippets from that
project, so this is talk will be rooted in real code that is actually in use.

LLVM is a great example because it contains a *lot* of performance sensitive
algorithms that use a wide variety of data structures. And the LLVM project and
developers are performance nuts so it tends to use very well optimized and tuned
utilities.

---
name: core-ds

## Core Data Structures:

1. Vector
1. Set
1. Map

???

The core DS set is really this small. A vector, a set, and a map.

Really, its even more simple as the map is built directly out of the set.

---
name: smallvector

### LLVM's vector

```
template <typename T, int N>
class SmallVector {
  ...
};
```

???
Despite the name "small", this type is used pervasively as the vector type of
choice in LLVM.

This is really the workhorse data structure, not unlike std::vector
- Everything uses it...
- Queue
- Worklist
- stack
- binary heap
- sorted set or map

In essence, just a small size optimized vector
- Useful to skip initial alloc even when large often
- Customizable "small" size makes it flexible for cases where reserving a large
  chunk of the stack is actually the best approach

---
name: smallvector-layout

### A small buffer pre-allocated inside the object

For example `SmallVector<int*, 1>` uses a memory layout like:

<table class="memory">
  <thead>
    <tr class="bytes">
      <th class="label">bytes</th>
      <th>0</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th>
      <th>8</th><th>9</th><th>10</th><th>11</th><th>12</th><th>13</th><th>14</th><th>15</th>
      <th>16</th><th>17</th><th>18</th><th>19</th><th>20</th><th>21</th><th>22</th><th>23</th>
      <th>24</th><th>25</th><th>26</th><th>27</th><th>28</th><th>29</th><th>30</th><th>31</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td class="label">members</td>
      <td colspan=8>pointer</td>
      <td colspan=8>size</td>
      <td colspan=8>capacity</td>
      <td colspan=8>inline buffer</td>
    </tr>
  </tbody>
</table>

???
We layout the inline buffer within the object. The
pointer just points into this buffer when in "small" mode.

---
name: why-not-std-vector
template: title-layout

### Why not `std::vector`? Iterator invalidation.

---
name: erase-small-size
template: layout

### `SmallVector` also supports *free* erasure of small size

(code for `SmallVectorImpl<T>` in an interface)

???
This trick comes from very careful usage of factoring the design.
- All the relevant APIs for SmallVector are provided by a base class.
- We pass the capacity down as we need it in the large form anyways.
- Allows zero-cost "erasure" of the small size as it is only needed to allocate.

---
name: smalldenseset

### LLVM's set structure: `SmallDenseSet`

- Not "dense", just uses open addressing and no buckets
- Small-size optimization layered on top
- Can even avoid hashing and just append when *very* small

---
name: smalldensemap

### LLVM's map structure is just a set with a key/value pair

---
name: done
template: title-layout

## We're done.

---
name: elephant

(elephant in the room picture)

--

## Why not just use allocators?

---

### (allocators code example)

---

### (allocators on an interface boundary example)

---

### (return a smallvector code example)

???
The real challenge with allocators is that they lose value semantics.

Consider this code, where the small vector can be returned by value. Doing this
with an allocator requires passing in the allocator, complicating the code and
making clients aware of the particular small size required.

With smallvector, even though the small size is exposed in the interface, users
typically just use auto and stop caring.

---

## Small-size optimization is best for values that are *small*!

---

## So how can we make the values *small*?

---

## First: give large objects *address identity*

???

---

### (vector of unique ptrs rather than objects, makes grow fast)

???
Really simple technique.

Downsides are that the separate allocation run the risk of undermining the
locality and cache friendliness of the data structures.

---

### (bumpptrallocator example)

???
To address the separate allocation problem, we often use a slab or "bump
pointer" allocator to allocate objects densely in memory at stable addresses.

Allocating slabs of large objects (especially if they're not uniformly sized)
and then building your set, map, or worklist data structures out of pointers to
them turns out to be incredibly efficient.

Consider, walking a vector of pointers to objects versus walking a list of
objects
- If the list is doubly linked, twice as much overhead
- much harder to have small size optimization keep all the pointers warm in cache
- Fewer dependencies - accessing the next element doesn't depend on accessing
  the first. in highly out-of-order modern processors, this can significantly
  improve their ability to hide memory access latencies


---

### (SmallVector and using index identity example code)

???
Sometimes, pointers don't work well or are still too large. In those cases we
will often use counted objects allocated in a single contiguous location and
have *index* identity instead of *address* identity. Same wins as with pointers,
but even more compact data if we can get away with 32bit or smaller indices.

---

## Second: aggressively pack bits

---

### Just made most of our data structure values pointers above:

(insert image of bits in a pointer)

???
Some of the bits in pointers aren't actually used

When necessary, we can even artificially align the types higher and get more
free bits. As more and more users have 64-bit address spaces, overaligned types
become very effective

---

### (code for PointerIntPair)

???
This lets us combine pointers with small integers. The code ends up being fully
generic.

---

### (code for putting a PointerEmbeddedInteger into a PointerIntPair)

???
And it isn't restricted to pointers. It can handle any "pointer like" object.

---

### (code for nesting a PointerIntPair inside another PointerIntPair)

???
And in fact, it is itself a pointer like object! It just consumes some of the
pointer-like alignment provided.

---

### (code for PointerSumType)

???
We can then use this to build still more abstractions such as a sum type across pointer like types with an enum descriminator

---

### (code for TinyPtrVector)

???
Then we can build another hybrid data structure on top of this by introducing a vector that is a pointer-like object, AND EVEN HAS A SMALL SIZE OPTIMIZATION!

---

### (code for DenseMap<K*, TinyPtrVector<V*>>)

???
One of the most important applications of this is to nest a vector within a map with high locality and very good scalaing properties.

---

### Third: use bitfields everywhere.

---

## Sometimes, you really need to impose ordering on containers...

???
Hash tables, open addressing and pointers all make this much harder to achieve.

---

### Where possible, sort vectors.

???
Sorted vectors are a wonderful thing. If you constantly need the ordering, keep
everything sorted and use appropriate algorithsm to update. If you only
occasionally need things ordered, sort on demand.

Note that everything more complex than sorting also works well here. For
example, in-vector trees and heaps are very fast and excellent structures.

---

### Sometimes, there isn't a useful sort-based ordering to use.

---

### (code for SetVector)

???
A very common pattern in those situations is just to keep a set and a vector.
This gives you insertion-order in the vector but set semantics. LLVM wraps this
up because it is so common. Of course, this delegates to the nicely small-size
optimized routines.

A really useful technique we haven't yet imployed is to take advantage of the
fact that the set is *also* a vector when small to have the small size
optimization be shared.

---

### (code for MapVector)

???
Naturally, all that applies for sets, applies for maps.

---

## mumble conclusion mumble

---

# Questions?

    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create({
        // Set the slideshow display ratio
        // Default: '4:3'
        // Alternatives: '16:9', ...
        ratio: '16:9',

        // Syntax highlighting theme
        highlightLanguage: 'cpp',
        highlightStyle: 'ir-black',
        highlightLines: true,
        highlightSpans: true,

        // Customize slide number label, either using a format string..
        slideNumberFormat: '(%current% / %total%)',
      });
    </script>
  </body>
</html>
