<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta charset="utf-8">
    <link href="https://fonts.googleapis.com/css?family=Oswald|Roboto|Roboto+Mono" rel="stylesheet">
    <style>
      body {
        font-family: 'Roboto', sans-serif;
        font-size: 120%
      }
      h1, h2, h3 {
        font-family: 'Oswald', sans-serif;
        font-weight: normal;
      }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      .remark-container {
        background-color: #000;
      }
      .remark-slide-scaler {
        -moz-box-shadow: 0 0 30px #000;
        -webkit-box-shadow: 0 0 30px #000;
        box-shadow: 0 0 30px #000;
      }
      .remark-slide-content {
        background-color: #000;
        background-size: cover;
        background-position: center;
        color: #f8f8f8;
        font-size: 32px;
        text-shadow: 0px 0px 16px #000, 0px 0px 32px #000;
        padding: 0.5em 1em 0.5em 1em
      }
      .remark-slide-content h1 {
        font-size: 85px
      }
      .remark-slide-content h2 {
        font-size: 75px
      }
      .remark-slide-content h3 {
        font-size: 75px
      }
      .remark-code, .remark-inline-code {
        font-family: 'Roboto Mono', monospace;
      }
      .remark-code {
        font-size: 22px;
      }
      .remark-code-line-highlighted {
        background-color: #000;
        border: 5px solid #F00;
        box-shadow: 0 0 30px #F00;
      }
      .remark-code-span-highlighted {
        background-color: #000;
        border: 5px solid #F00;
        box-shadow: 0 0 30px #F00;
      }
      .left-col {
        float: left;
        width: 49%;
      }
      .right-col {
        float: right;
        width: 49%;
      }

      #slide-llvm {
        background-position: -50% 60%;
        background-size: 120%;
      }
    </style>
  </head>
  <body>
    <textarea id="source">

name: title-layout
layout: true
class: center, middle, title

---
name: basic-layout
layout: true
class: left, top

---
name: title
template: title-layout

# High Performance Code 201: Hybrid Data Structures

.footnote[Chandler Carruth, [chandlerc@gmail.com], [@chandlerc1024](https://twitter.com/chandlerc1024)]

???
Intro:
- I'm Chandler Carruth
- I'm the lead for Google's C++ PL platform
- Also one of the core developers on the LLVM open source compiler project

I'm going to walk you through the essential hybrid data structures, describe why
they're fast, and how to use them solve really interesting problems.

---
name: llvm
template: basic-layout
background-image: url(DragonFull.png)

## LLVM
- Performance sensitive
- Hacked on by performance nuts

???
These DS aren't just hypothetical. They actually make up the core data
structures used by the LLVM project. I'll be showing code snippets from that
project, so this is talk will be rooted in real code that is actually in use.

LLVM is a great example because it contains a *lot* of performance sensitive
algorithms that use a wide variety of data structures. And the LLVM project and
developers are performance nuts so it tends to use very well optimized and tuned
utilities.

---
name: core-ds
template: title-layout

## Vectors and sets, and maps, oh my!

???

The core DS set is really this small. A vector, a set, and a map.

Really, its even more simple as the map is built directly out of the set.

---
name: smallvector
template: basic-layout

```
template <typename T, int N>
class SmallVector {
  ...
};
```

???
Despite the name "small", this type is used pervasively as the vector type of
choice in LLVM.

This is really the workhorse data structure, not unlike std::vector
- Everything uses it...
- Queue
- Worklist
- stack
- binary heap
- sorted set or map

In essence, just a small size optimized vector
- Useful to skip initial alloc even when large often
- Customizable "small" size makes it flexible for cases where reserving a large
  chunk of the stack is actually the best approach

---
name: smallvector-layout
template: basic-layout

### A small buffer pre-allocated inside the object

For example `SmallVector<int*, 1>` uses a memory layout like:

<table class="memory">
  <thead>
    <tr class="bytes">
      <th class="label">bytes</th>
      <th>0</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th>
      <th>8</th><th>9</th><th>10</th><th>11</th><th>12</th><th>13</th><th>14</th><th>15</th>
      <th>16</th><th>17</th><th>18</th><th>19</th><th>20</th><th>21</th><th>22</th><th>23</th>
      <th>24</th><th>25</th><th>26</th><th>27</th><th>28</th><th>29</th><th>30</th><th>31</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td class="label">members</td>
      <td colspan=8>pointer</td>
      <td colspan=8>size</td>
      <td colspan=8>capacity</td>
      <td colspan=8>inline buffer</td>
    </tr>
  </tbody>
</table>

???
We layout the inline buffer within the object. The
pointer just points into this buffer when in "small" mode.

---
name: why-not-std-vector
template: title-layout

### Why not `std::vector`? Iterator invalidation.

---
name: erase-small-size
template: basic-layout

.left-col[
```
template <typename T>
class SmallVectorImpl {
  T *begin, *end;
  size_t capacity;

protected:
  SmallVectorImpl(T *begin, T *end,
                  size_t capacity)
      : begin(begin), end(end),
        capacity(capacity) {}

public:
  iterator begin();
  iterator end();

  void push_back(const T &element);
  void pop_back();

  // ...
};
```
]
.right-col[
```
template <typename T, int N>
class SmallVector
    : public SmallVectorImpl<T> {
  char buffer[sizeof(T) * N];

public:
  SmallVector()
      : SmallVectorImpl((T *)buffer,
                        (T *)buffer,
                        N) {}

  // ...
};
```
]

???
`SmallVector` also supports *free* erasure of small size

This trick comes from very careful usage of factoring the design.
- All the relevant APIs for SmallVector are provided by a base class.
- We pass the capacity down as we need it in the large form anyways.
- Allows zero-cost "erasure" of the small size as it is only needed to allocate.

---
name: smalldenseset
template: title-layout

### Set: small-size, open addressing hash table

???
- Not "dense", just uses open addressing and no buckets
- Small-size optimization layered on top
- Can even avoid hashing and just append when *very* small

---
name: smalldenseset-small
template: basic-layout

![SmallDenseSet memory layout](small-set.svg)

---
name: smalldenseset-linear
template: basic-layout

![SmallDenseSet memory layout](small-set-linear.svg)

---
name: smalldenseset-probe
template: basic-layout

![SmallDenseSet memory layout](small-set-probe.svg)

---
name: smalldensemap
template: title-layout

### Map: just a set with a key/value pair

---
name: done
template: title-layout

## We're done.

---
name: elephant
template: title-layout
background-image: url(elephant.jpg)

--

## Why not just use allocators?

---
name: allocators
template: basic-layout

```
template <class T, int N>
using SmallVector =
    std::vector<T, short_alloc<T, N>>;

void f() {
  SmallVector<int, 4>::allocator_type::arena_type a;
  SmallVector<int> v{a};
  // ...
}
```

---
name: allocator-interface-boundary
template: basic-layout

```
template <class T, int N>
using SmallVector =
    std::vector<T, short_alloc<T, N>>;

void g(SmallVector<int, `4`> &v);

void f() {
  SmallVector<int, `8`>::allocator_type::arena_type a;
  SmallVector<int> v{a};
  // ...
  g(v); // BOOOM
}
```

---
name: return-small-vector
template: basic-layout

```
template <class T, int N>
using SmallVector =
    std::vector<T, short_alloc<T, N>>;

`SmallVector<T, 4>` f() {
  SmallVector<int, 4>::allocator_type::arena_type a;
  SmallVector<int> v{a};
  // ...
  g(v); // You're gonna have a bad time...
}
```

???
The real challenge with allocators is that they lose value semantics.

Consider this code, where the small vector can be returned by value. Doing this
with an allocator requires passing in the allocator, complicating the code and
making clients aware of the particular small size required.

With smallvector, even though the small size is exposed in the interface, users
typically just use auto and stop caring.

---
name: small-size
template: title-layout

## Small-size optimization is best for values that are *small*!

---
name: make-values-small
template: title-layout

## So how can we make the values *small*?

---
name: address-identity
template: title-layout

## First: give large objects *address identity*

???

---
name: vector-unique-ptr
template: basic-layout

```
SmallVector<std::unique_ptr<BigObject>, 4> Objects;
```

???
Really simple technique.

Downsides are that the separate allocation run the risk of undermining the
locality and cache friendliness of the data structures.

---
name: bump-ptr-allocator
template: basic-layout

```
class BumpPtrAllocator {
  constexpr int SlabSize = 4096;
  SmallVector<void *, 4> Slabs;
  void *CurPtr;
  char *End;

public:
  void *Allocate(int Size) {
    if (Size < (End - CurPtr)) {
      void *Ptr = CurPtr;
      CurPtr += Size;
      return Ptr;
    }

    void *Ptr = malloc(SlabSize);
    Slabs.push_back(Ptr);
    CurPtr = Ptr + Size;
    End = Ptr + SlabSize;
    return Ptr;
  }

  // ...
};
```

???
To address the separate allocation problem, we often use a slab or "bump
pointer" allocator to allocate objects densely in memory at stable addresses.

Allocating slabs of large objects (especially if they're not uniformly sized)
and then building your set, map, or worklist data structures out of pointers to
them turns out to be incredibly efficient.

Consider, walking a vector of pointers to objects versus walking a list of
objects
- If the list is doubly linked, twice as much overhead
- much harder to have small size optimization keep all the pointers warm in cache
- Fewer dependencies - accessing the next element doesn't depend on accessing
  the first. in highly out-of-order modern processors, this can significantly
  improve their ability to hide memory access latencies


---
name: index-identity
template: title-layout

### If pointers are too large, use an index into a vector.

???
Sometimes, pointers don't work well or are still too large. In those cases we
will often use counted objects allocated in a single contiguous location and
have *index* identity instead of *address* identity. Same wins as with pointers,
but even more compact data if we can get away with 32bit or smaller indices.

---
name: bitpacking
template: title-layout

## Second: aggressively pack bits

---
name: everything-is-a-pointer
template: title-layout

![Give me a pointer!](http://imgs.xkcd.com/comics/pointers.png)

???
We just made everything a pointer, what can we do with those?

Well, real pointers don't look quite like the ones in xkcd...

---
name: pointer-bits-available
template: basic-layout

```
Breakpoint 1, main () at test.cpp:7
7         S *s = new S;
(gdb) n
8         return 0;
(gdb) p/a s
$2 = 0x402010
(gdb) p/t s
$3 = 10000000010000000010000
```

???
Some of the bits in pointers aren't actually used due to alignment.

When necessary, we can even artificially align the types higher and get more
free bits. As more and more users have 64-bit address spaces, overaligned types
become very effective

---
name: pointer-int-pair
template: basic-layout

```
template <typename T, int IntBits, typename IntT = unsigned>
class PointerIntPair {
  constexpr int PtrBitsFree = log2(alignof(T));
  constexpr int IntShift = PtrBitsFree - IntBits;
  constexpr uintptr_t IntMask =
      (uintptr_t)(((intptr_t)1 << IntBits) - 1);
  constexpr uintptr_t PtrMask =
      ~(uintptr_t)(((intptr_t)1 << PtrBitsFree) - 1);

  uintptr_t Value;

public:
  T* getPointer() const {
    return reinterpret_cast<T*>(Value & PtrMask);
  }
  IntType getInt() const {
    return (IntType)((Value >> IntShift) & IntMask);
  }
```

???
This lets us combine pointers with small integers. The code ends up being fully
generic.

---
name: pointer-embedded-int
template: basic-layout

### (code for putting a PointerEmbeddedInteger into a PointerIntPair)

???
And it isn't restricted to pointers. It can handle any "pointer like" object.

---
name: pointer-int-pair-nested
template: basic-layout

### (code for nesting a PointerIntPair inside another PointerIntPair)

???
And in fact, it is itself a pointer like object! It just consumes some of the
pointer-like alignment provided.

---
name: pointer-sum-type
template: basic-layout

### (code for PointerSumType)

???
We can then use this to build still more abstractions such as a sum type across pointer like types with an enum descriminator

---
name: tiny-ptr-vector
template: basic-layout

### (code for TinyPtrVector)

???
Then we can build another hybrid data structure on top of this by introducing a vector that is a pointer-like object, AND EVEN HAS A SMALL SIZE OPTIMIZATION!

---
name: dense-map-tiny-ptr-vector
template: basic-layout

### (code for DenseMap<K*, TinyPtrVector<V*>>)

???
One of the most important applications of this is to nest a vector within a map with high locality and very good scalaing properties.

---
name: bitfields
template: title-layout

### Third: use bitfields everywhere.

---
name: ordering
template: title-layout

## Sometimes, you really need to impose ordering on containers...

???
Hash tables, open addressing and pointers all make this much harder to achieve.

---
name: sort
template: title-layout

### Where possible, sort vectors.

???
Sorted vectors are a wonderful thing. If you constantly need the ordering, keep
everything sorted and use appropriate algorithsm to update. If you only
occasionally need things ordered, sort on demand.

Note that everything more complex than sorting also works well here. For
example, in-vector trees and heaps are very fast and excellent structures.

---
name: not-always-ordered
template: title-layout

### Sometimes, there isn't a useful sort-based ordering to use.

---
name: setvector
template: basic-layout

### (code for SetVector)

???
A very common pattern in those situations is just to keep a set and a vector.
This gives you insertion-order in the vector but set semantics. LLVM wraps this
up because it is so common. Of course, this delegates to the nicely small-size
optimized routines.

A really useful technique we haven't yet imployed is to take advantage of the
fact that the set is *also* a vector when small to have the small size
optimization be shared.

---
name: mapvector
template: basic-layout

### (code for MapVector)

???
Naturally, all that applies for sets, applies for maps.

---
name: conclusion
template: title-layout

## mumble conclusion mumble

---
name: questions
template: title-layout

# Questions?

    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create({
        // Set the slideshow display ratio
        // Default: '4:3'
        // Alternatives: '16:9', ...
        ratio: '16:9',

        // Syntax highlighting theme
        highlightLanguage: 'cpp',
        highlightStyle: 'ir-black',
        highlightLines: true,
        highlightSpans: true,

        // Customize slide number label, either using a format string..
        slideNumberFormat: '(%current% / %total%)',
      });
    </script>
  </body>
</html>
